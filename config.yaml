asr_model: 
  task: "automatic-speech-recognition"
  model_tag: "openai/whisper-small"
  chunk_length: 30

image_model:
  model_name: "llava:latest"

image_dir: "images"
session_path: "sessions"
pdf_path: "docs"

models: ["Gemma", "Llava", "TinyLlama", "Llama2"]
model_map: { 
  "Gemma": "KnowlyGemma:latest", 
  "Llava": "KnowlyLlava:latest",
  "TinyLlama": "KnowlyTinyLlama:latest",
  "Llama2": "KnowlyLlama2",
}

embedding:
  embedding_storage: "vectorstore"

text_split:
  separators: ["\n\n","\n"]
  chunk_size: 2000
  chunk_overlap: 100

allowed_doc_formats: ["pdf"]
allowed_image_formats: ["jpg", "jpeg", "png"]
