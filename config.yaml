asr_model: 
  task: "automatic-speech-recognition"
  model_tag: "openai/whisper-small"
  chunk_length: 30

image_model:
  model_name: "llava:latest"

image_dir: "images"
session_path: "sessions"
pdf_path: "docs"

models: ["Gemma-2b", "TinyLlama-1.1b", "Llava-7b"]
model_map: {
  "Gemma-2b": "KnowlyGemma:latest",
  "TinyLlama-1.1b": "KnowlyTinyLlama:latest",
  "Llava-7b": "KnowlyLlava:latest",
}

embedding:
  embedding_storage: "vectorstore"

text_split:
  separators: ["\n\n","\n"]
  chunk_size: 2000
  chunk_overlap: 100

allowed_doc_formats: ["pdf"]
allowed_image_formats: ["jpg", "jpeg", "png"]